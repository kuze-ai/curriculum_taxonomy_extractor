{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "# URLs\n",
    "base_url = 'https://kcserevision.com/'\n",
    "target_url = 'https://kcserevision.com/grade-6-kicd-curriculum-designs-pdf/'\n",
    "\n",
    "# Your login credentials\n",
    "credentials = {\n",
    "    'swpm_user_name': 'njoroge12',\n",
    "    'swpm_password': 'njoroge'\n",
    "}\n",
    "\n",
    "# Create a session object\n",
    "session = requests.Session()\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Attempt to login\n",
    "response = session.post(base_url, headers=headers, data=credentials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed https://kcserevision.com/grade-1-2-3-4-cbc-lesson-plans/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/2024-grade-7-8-cbc-junior-secondary-resources/\n",
      "Processed https://kcserevision.com/grade-8-junior-secondary-schemes-of-work/\n",
      "Processed https://kcserevision.com/grade-8-junior-secondary-exams/\n",
      "Processed https://kcserevision.com/grade-8-junior-secondary-assignments/\n",
      "Processed https://kcserevision.com/grade-8-junior-secondary-notes/\n",
      "Processed https://kcserevision.com/grade-8-junior-secondary-lesson-plans/\n",
      "Processed https://kcserevision.com/grade-8-curriculum-designs-kicd/\n",
      "Processed https://kcserevision.com/2024-grade-8-assessment-and-scoresheet/\n",
      "Processed https://kcserevision.com/grade-8-term-1-2-3-opener-mid-end-exams/\n",
      "Processed https://kcserevision.com/2024-grade-7-schemes-of-work-term-1-2-3/\n",
      "Processed https://kcserevision.com/2024-jss-grade-7-term-1-2-3-exams/\n",
      "Processed https://kcserevision.com/2024-grade-7-jss-notes-term-1-2-3/\n",
      "Processed https://kcserevision.com/2024-grade-7-term-1-2-3-lesson-plans/\n",
      "Processed https://kcserevision.com/grade-7-kicd-curriculum-designs/\n",
      "Processed https://kcserevision.com/2024-grade-7-assessment-and-scoresheet/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-5-6-7-8-cbc-revision/\n",
      "Processed https://kcserevision.com/grade-1-2-3-notes-cbc-resources/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-revision-materials-download-page/\n",
      "Processed https://kcserevision.com/grade-1-2-3-4-cbc-revision-materials/\n",
      "Processed https://kcserevision.com/2024-grade-7-8-cbc-junior-secondary-resources/\n",
      "Processed https://kcserevision.com/2024-grade-1-2-3-4-5-6-cbc-resources/\n",
      "Processed https://kcserevision.com/2024-grade-7-8-cbc-junior-secondary-resources/\n",
      "Processed https://kcserevision.com/download-kenya-lesson-plans/\n",
      "Google Drive links from all grade pages saved to ../data/processed/google_drive_links.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "def extract_google_drive_links(session, url, headers):\n",
    "    \"\"\"Extracts Google Drive links, their titles, and the source URL from a given page URL.\"\"\"\n",
    "    response = session.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    drive_links = [(a.get_text(strip=True), a['href'], url.replace('https://kcserevision.com', '')) for a in soup.find_all('a', href=re.compile(r\"https://drive\\.google\\.com/.*\"))]\n",
    "    return drive_links\n",
    "\n",
    "# URLs\n",
    "base_url = 'https://kcserevision.com/'\n",
    "initial_url = 'https://kcserevision.com'\n",
    "\n",
    "# Create a session object\n",
    "session = requests.Session()\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Directory to save the file\n",
    "processed_dir = '../data/processed/'\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "\n",
    "# Filename for the output\n",
    "output_filename = os.path.join(processed_dir, 'google_drive_links.txt')\n",
    "\n",
    "# Set to keep track of unique URLs\n",
    "unique_urls = set()\n",
    "\n",
    "# Process and save unique links\n",
    "with open(output_filename, 'w') as file:\n",
    "    # Get the initial page with the grade links\n",
    "    response = session.get(initial_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all links that start with \"GRADE \"\n",
    "    grade_links = [a['href'] for a in soup.find_all('a', href=True) if a.text.startswith(\"GRADE \")]\n",
    "\n",
    "    for grade_url in grade_links:\n",
    "        drive_links = extract_google_drive_links(session, grade_url, headers)\n",
    "        for title, link, source_url in drive_links:\n",
    "            full_url = f\"{link}\"\n",
    "            if full_url not in unique_urls:\n",
    "                unique_urls.add(full_url)\n",
    "                file.write(f\"{link}\\n\")\n",
    "        print(f\"Processed {grade_url}\")\n",
    "        \n",
    "print(f\"Google Drive links from all grade pages saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Re-running the code due to execution state reset\n",
    "# Reading the Google Drive links file to process for removing duplicates based on file or folder ID\n",
    "file_path = '../data/processed/google_drive_links_v1.txt'\n",
    "\n",
    "# Function to extract unique Google Drive file or folder IDs from the URL\n",
    "def extract_unique_ids(file_path):\n",
    "    unique_ids = set()\n",
    "    unique_lines = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            # Extracting file/folder ID from the Google Drive URL\n",
    "            match = re.search(r'drive\\.google\\.com/(?:file/d/|folders/)([a-zA-Z0-9_-]+)', line)\n",
    "            if match:\n",
    "                file_id = match.group(1)\n",
    "                # Add line to unique list if ID is unique\n",
    "                if file_id not in unique_ids:\n",
    "                    unique_ids.add(file_id)\n",
    "                    unique_lines.append(line)\n",
    "\n",
    "    return unique_lines\n",
    "\n",
    "# Extracting unique lines based on Google Drive file or folder IDs\n",
    "unique_google_drive_links = extract_unique_ids(file_path)\n",
    "\n",
    "# Count of unique links\n",
    "len(unique_google_drive_links)\n",
    "\n",
    "## Write unique links to file\n",
    "# Directory to save the file\n",
    "processed_dir = '../data/processed/'\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "\n",
    "# Filename for the output\n",
    "output_filename = os.path.join(processed_dir, 'google_drive_links_v1.unq.txt')\n",
    "\n",
    "# Write unique links to file\n",
    "with open(output_filename, 'w') as file:\n",
    "    for line in unique_google_drive_links:\n",
    "        file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGRICULTURE SCHEMES': {'SCHEMES': ['GRADE 6 TERM 1 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/11Csc06oFzmsRvNZ7vFOuRv2GPfmzQZ7g/view?usp=drive_web\\n',\n",
       "   'GRADE 6 TERM 2 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1EmDBkEU8yoQ-0fSTQkbvNP3qPu4zK5AH/view?usp=drive_web\\n',\n",
       "   'GRADE 6 TERM 3 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1PiXakw8z3k2bmtsMzBIcBrKVv4qDGRv9/view?usp=drive_web\\n',\n",
       "   'GRADE 5 TERM 1 AGRICULTURE SCHEMES (1).docx: https://drive.google.com/file/d/1D2OYub-FPNivGVaBRrt-nXc_eNa7P3Tf/view?usp=drive_web\\n',\n",
       "   'GRADE 5 TERM 1 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1PfF9tDxXwvCMBNDwsLnpgSA5isjuepfX/view?usp=drive_web\\n',\n",
       "   'GRADE 5 TERM 2 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1eV9bnpbJFwXt0GF47Te9RDw_vix_s71R/view?usp=drive_web\\n',\n",
       "   'GRADE 5 TERM 3 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1ln18_76pFjLbPBnp7NM2R8qKAOvI061m/view?usp=drive_web\\n',\n",
       "   'GRADE 4 TERM 1 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1B9JYoG1qrJHZXE-seHJXXxdQF8IEbxMl/view?usp=drive_web\\n',\n",
       "   'GRADE 4 TERM 2 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1dkAWJV9_o7nisY-0-5LVTYeLxNVi8Urj/view?usp=drive_web\\n',\n",
       "   'GRADE 4 TERM 3 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1sq4F1wXhVtfR2iSsoH33mO-4UNqlOylg/view?usp=drive_web\\n',\n",
       "   'GRADE 3 TERM 1 AGRICULTURE SCHEMES.docx: https://drive.google.com/file/d/1Saosg4yxV7DbvsIvmDkVhbM06oRtdeYQ/view?usp=drive_web\\n']},\n",
       " 'ART CRAFT SCHEMES': {'SCHEMES': ['GRADE 6 TERM 1 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1_BoTRTCUIqRHpVBmU2tkWo4i4f4nuspA/view?usp=drive_web\\n',\n",
       "   'GRADE 5 TERM 2 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1zptk0kiS1c3ZVWexNqsluUkHXElv-JEx/view?usp=drive_web\\n',\n",
       "   'GRADE 4 TERM 2 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1pqfGldkVk4habhyS9sZlV_vM5XIXzqI0/view?usp=drive_web\\n',\n",
       "   'GRADE 4 TERM 3 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1fBThfG2ykcUh9SG9cq0mcc13nkVdJ1OC/view?usp=drive_web\\n',\n",
       "   'GRADE 3 TERM 2 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1XUeC77lbEdGW6ojZdFN_oUEOM4qBVUkD/view?usp=drive_web\\n',\n",
       "   'GRADE 2 TERM 2 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1iPUvXyIqh9p2yVOqGKFev_anYl4Dbvsa/view?usp=drive_web\\n',\n",
       "   'GRADE 2 TERM 3 ART CRAFT SCHEMES (1).docx: https://drive.google.com/file/d/1zCtcftxsvAauuNXQYqAcvBjQdkod1vlt/view?usp=drive_web\\n',\n",
       "   'GRADE 2 TERM 3 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1t_32ruEUdvnhO8IcOxidbumPmcwN7k0G/view?usp=drive_web\\n',\n",
       "   'GRADE 1 TERM 1 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1BGxI_RkZqVqCImZaFugHcpg3zlfwfZSc/view?usp=drive_web\\n',\n",
       "   'GRADE 1 TERM 2 ART CRAFT SCHEMES.docx: https://drive.google.com/file/d/1A_RxU_6TYijZm2fOAu-O7N5FYdaC-tDB/view?usp=drive_web\\n']}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import os\n",
    "#Regular expressions for extracting subject and type\n",
    "subject_pattern = re.compile(r\"GRADE \\d+ TERM \\d+ (\\w+[\\w\\s]*)(?: SCHEMES| LESSON PLANS| NOTES| EXAMS| ACTIVITIES| ASSIGNMENTS)?\", re.IGNORECASE)\n",
    "type_pattern = re.compile(r\"(SCHEMES|LESSON PLANS|NOTES|EXAMS|ACTIVITIES|ASSIGNMENTS)\", re.IGNORECASE)\n",
    "\n",
    "# Organize links by subject and type\n",
    "organized_links = defaultdict(lambda: defaultdict(list))\n",
    "for line in unique_google_drive_links:\n",
    "    subject_match = subject_pattern.search(line)\n",
    "    type_match = type_pattern.search(line)\n",
    "\n",
    "    if subject_match and type_match:\n",
    "        subject = subject_match.group(1).strip().upper()\n",
    "        type_ = type_match.group(1).strip().upper()\n",
    "        organized_links[subject][type_].append(line)\n",
    "\n",
    "# Writing to files\n",
    "output_dir = \"data/processed/organized_links\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for subject, types in organized_links.items():\n",
    "    subject_dir = os.path.join(output_dir, subject)\n",
    "    os.makedirs(subject_dir, exist_ok=True)\n",
    "\n",
    "    for type_, links in types.items():\n",
    "        file_name = os.path.join(subject_dir, f\"{type_}.txt\")\n",
    "        with open(file_name, 'w') as file:\n",
    "            for link in links:\n",
    "                file.write(link + '\\n')\n",
    "\n",
    "# Return a sample of the organized structure for demonstration\n",
    "sample_output = {subject: dict(types) for subject, types in list(organized_links.items())[:2]}\n",
    "sample_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in successfully.\n",
      "Google Drive links saved to ../data/processed/google_drive_links.txt\n"
     ]
    }
   ],
   "source": [
    "# Check if login was successful by looking at cookies or response content\n",
    "if 'swpm_session' in session.cookies:\n",
    "    print(\"Logged in successfully.\")\n",
    "\n",
    "    # Get the page with the files\n",
    "    response = session.get(target_url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all Google Drive links and their titles\n",
    "    drive_links = [(a.get_text(strip=True), a['href']) for a in soup.find_all('a', href=re.compile(r\"https://drive\\.google\\.com/.*\"))]\n",
    "\n",
    "    # Directory to save the file\n",
    "    processed_dir = '../data/processed/'\n",
    "    if not os.path.exists(processed_dir):\n",
    "        os.makedirs(processed_dir)\n",
    "\n",
    "    # Save the links and titles to a file\n",
    "    with open(os.path.join(processed_dir, 'google_drive_links.txt'), 'w') as file:\n",
    "        for title, link in drive_links:\n",
    "            file.write(f\"{title}: {link}\\n\")\n",
    "        print(f\"Google Drive links saved to {os.path.join(processed_dir, 'google_drive_links.txt')}\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to login.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Function to create subdirectories based on grade and thematic area\n",
    "def create_subdirectory(download_dir, filename):\n",
    "    grade = re.search(r'GRADE \\d+', filename, re.IGNORECASE)\n",
    "    thematic_area = re.search(r'(SCHEMES|EXAMS|ASSIGNMENTS|NOTES|LESSON PLANS|CURRICULUM|ASSESSMENT AND SCORESHEET|TERM \\d+)', filename, re.IGNORECASE)\n",
    "    \n",
    "    subdirectory = 'Miscellaneous'\n",
    "    if grade and thematic_area:\n",
    "        subdirectory = f\"{grade.group(0).capitalize()}/{thematic_area.group(0).capitalize()}\"\n",
    "    \n",
    "    subdirectory_path = os.path.join(download_dir, subdirectory)\n",
    "    if not os.path.exists(subdirectory_path):\n",
    "        os.makedirs(subdirectory_path)\n",
    "    \n",
    "    return subdirectory_path\n",
    "\n",
    "# # Paths\n",
    "# file_path = '/mnt/data/processed/cur_links.txt'  # Update with the correct file path\n",
    "# download_directory = '/mnt/data/cur_downloads/'\n",
    "# download_log_path = '/mnt/data/interim/cur_downloaded_files.log'\n",
    "# error_log_path = '/mnt/data/interim/cur_error_files.log'\n",
    "\n",
    "\n",
    "# Paths\n",
    "file_path = '../data/processed/math_links.txt'\n",
    "download_directory = '../data/math_downloads/'\n",
    "download_log_path = '../data/interim/math_downloaded_files.log'\n",
    "error_log_path = '../data/interim/math_error_files.log'\n",
    "\n",
    "# Regular expression pattern for file and folder URLs\n",
    "file_pattern = r'drive\\.google\\.com/file/d/([a-zA-Z0-9_-]+)/view'\n",
    "folder_pattern = r'drive\\.google\\.com/drive/folders/([a-zA-Z0-9_-]+)'\n",
    "\n",
    "# Ensure download directory exists\n",
    "if not os.path.exists(download_directory):\n",
    "    os.makedirs(download_directory)\n",
    "\n",
    "# Load downloaded files log\n",
    "if os.path.exists(download_log_path):\n",
    "    with open(download_log_path, 'r') as log_file:\n",
    "        downloaded_files = log_file.read().splitlines()\n",
    "else:\n",
    "    downloaded_files = []\n",
    "\n",
    "# Load error log\n",
    "if os.path.exists(error_log_path):\n",
    "    with open(error_log_path, 'r') as error_file:\n",
    "        failed_downloads = error_file.read().splitlines()\n",
    "else:\n",
    "    failed_downloads = []\n",
    "\n",
    "# Process links\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        if line in downloaded_files or line in failed_downloads:\n",
    "            continue  # Skip if already processed\n",
    "\n",
    "        file_match = re.search(file_pattern, line)\n",
    "        folder_match = re.search(folder_pattern, line)\n",
    "\n",
    "        if file_match:\n",
    "            try:\n",
    "                file_id = file_match.group(1)\n",
    "                filename = line.split(':')[0].strip()\n",
    "                download_link = f'https://drive.google.com/uc?id={file_id}&export=download'\n",
    "                \n",
    "                subdirectory_path = create_subdirectory(download_directory, filename)\n",
    "                output_path = os.path.join(subdirectory_path, filename)\n",
    "                \n",
    "                gdown.download(download_link, output_path, quiet=False, use_cookies=False)\n",
    "                \n",
    "                with open(download_log_path, 'a') as log_file:\n",
    "                    log_file.write(f\"{line}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {line.strip()}. Error: {e}\")\n",
    "                with open(error_log_path, 'a') as error_file:\n",
    "                    error_file.write(f\"{line}\\n\")\n",
    "        elif folder_match:\n",
    "            try:\n",
    "                folder_id = folder_match.group(1)\n",
    "                folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
    "                \n",
    "                folder_download_path = os.path.join(download_directory, \"Folders\")\n",
    "                if not os.path.exists(folder_download_path):\n",
    "                    os.makedirs(folder_download_path)\n",
    "                \n",
    "                gdown.download_folder(folder_url, output=folder_download_path, quiet=False, use_cookies=False)\n",
    "                \n",
    "                with open(download_log_path, 'a') as log_file:\n",
    "                    log_file.write(f\"{line}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download folder {line.strip()}. Error: {e}\")\n",
    "                with open(error_log_path, 'a') as error_file:\n",
    "                    error_file.write(f\"{line}\\n\")\n",
    "        else:\n",
    "            print(f\"Could not extract file ID from line: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Function to create subdirectories based on grade and thematic area\n",
    "def create_subdirectory(download_dir, filename):\n",
    "    grade = re.search(r'GRADE \\d+', filename, re.IGNORECASE)\n",
    "    thematic_area = re.search(r'(SCHEMES|EXAMS|ASSIGNMENTS|NOTES|LESSON PLANS|CURRICULUM|ASSESSMENT AND SCORESHEET|TERM \\d+)', filename, re.IGNORECASE)\n",
    "    \n",
    "    subdirectory = 'Miscellaneous'\n",
    "    if grade and thematic_area:\n",
    "        subdirectory = f\"{grade.group(0).capitalize()}/{thematic_area.group(0).capitalize()}\"\n",
    "    \n",
    "    subdirectory_path = os.path.join(download_dir, subdirectory)\n",
    "    if not os.path.exists(subdirectory_path):\n",
    "        os.makedirs(subdirectory_path)\n",
    "    \n",
    "    return subdirectory_path\n",
    "\n",
    "# Paths\n",
    "file_path = '../data/processed/cur_links.txt'\n",
    "download_directory = '../data/cur_downloads/'\n",
    "download_log_path = '../data/interim/cur_downloaded_files.log'\n",
    "error_log_path = '../data/interim/cur_error_files.log'\n",
    "\n",
    "# Regular expression pattern to extract file ID from Google Drive link\n",
    "pattern = r'drive\\.google\\.com/file/d/([a-zA-Z0-9_-]+)/view'\n",
    "\n",
    "# Ensure download directory exists\n",
    "if not os.path.exists(download_directory):\n",
    "    os.makedirs(download_directory)\n",
    "\n",
    "# Load downloaded files log\n",
    "if os.path.exists(download_log_path):\n",
    "    with open(download_log_path, 'r') as log_file:\n",
    "        downloaded_files = log_file.read().splitlines()\n",
    "else:\n",
    "    downloaded_files = []\n",
    "\n",
    "# Load error log\n",
    "if os.path.exists(error_log_path):\n",
    "    with open(error_log_path, 'r') as error_file:\n",
    "        failed_downloads = error_file.read().splitlines()\n",
    "else:\n",
    "    failed_downloads = []\n",
    "\n",
    "# Process links\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        if line in downloaded_files or line in failed_downloads:\n",
    "            continue  # Skip if already processed\n",
    "\n",
    "        match = re.search(pattern, line)\n",
    "        if match:\n",
    "            try:\n",
    "                file_id = match.group(1)\n",
    "                filename = line.split(':')[0].strip()\n",
    "                download_link = f'https://drive.google.com/uc?id={file_id}'\n",
    "                \n",
    "                subdirectory_path = create_subdirectory(download_directory, filename)\n",
    "                output_path = os.path.join(subdirectory_path, filename)\n",
    "                \n",
    "                gdown.download(download_link, output_path, quiet=False)\n",
    "                \n",
    "                with open(download_log_path, 'a') as log_file:\n",
    "                    log_file.write(f\"{line}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {line.strip()}. Error: {e}\")\n",
    "                with open(error_log_path, 'a') as error_file:\n",
    "                    error_file.write(f\"{line}\\n\")\n",
    "        else:\n",
    "            print(f\"Could not extract file ID from line: {line}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
